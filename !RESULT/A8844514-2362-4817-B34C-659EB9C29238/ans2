Под параллельной программой в рамках OpenMP понимается программа, для которой в специально указываемых при помощи директив местах - параллельных фрагментах - исполняемый программный код может быть разделен на несколько раздельных командных потоков (threads). В общем виде программа представяется в виде набора последовательных (однопотоковых) и параллельных (многопотоковых) участков программного кода.
Важно отметить, что разделение вычислений между потоками осуществляется под управлением соответствующих директив OpenMP. Равномерное распределение вычислительной нагрузки - балансировка (load balancing) - имеет принципиальное значение для получения максимально возможного ускорения выполнения параллельной программы.
Потоки могут выполняться на разных процессорах (процессорных ядрах) либо могут группироваться для исполнения на одном вычислительном элементе (в этом случае их исполнение осуществляется в режиме разделения времени). В предельном случае для выполнения параллельной программы может использоваться один процессор - как правило, такой способ применяется для начальной проверки правильности параллельной программы.
Количество потоков определяется в начале выполнения параллельных фрагментов программы и обычно совпадает с количеством имеющихся вычислительных элементов в системе, изменение количества создаваемых потоков может быть выполнено при помощи целого ряд средств OpenMP. Все потоки в параллельных фрагментах программы последовательно перенумерованы от 0 до np-1, где np - есть общее количество потоков. Номер потока также может быть получен при помощи функции OpenMP.
Использование в технологии Open MP потоков для организации параллелизма позволяет учесть преимущества многопроцессорных вычислительных систем с общей памятью. Прежде всего, потоки одной и той же параллельной программы выполняются в общем адресном пространстве, что обеспечивает возможность использования общих данных для параллельно выполняемых потоков без каких-либо трудоемких межпроцессорных передач сообщений (в отличие от процессов в технологии MPI для систем с распределенной памятью). Кроме того, управление потоками (создание, приостановка, активизация, завершение) требует меньше накладных расходов для ОС по сравнению с процессами.
Потоки исполняются в общем адресном пространстве параллельно программы. Как результат, взаимодействие параллельных потоков можно организовать через использование общих данных, являющихся доступными для всех потоков. Наиболее простая ситуация состоит в использовании общих данных только для чтения. В случае же, когда общие данные могут изменяться несколькими потоками, необходимы специальные усилия для организации правильного взаимодействия. На самом деле, пусть два потока исполняют один и тот же программный код
n = n + 1
для общей переменной n. Тогда в зависимости от условий выполнения данная операция может быть выполнена поочередно (что приведет к получению правильного результата) или же оба потока могут одновременно прочитать значение переменной n, одновременно увеличить и записать в эту переменную новое значение (как результат, будет получено неправильное значение). Подобная ситуация , когда результат вычислений зависит от темпа выполнения потоков, получил наименование гонки потоков (race conditions). Для исключения гонки необходимо обеспечить, чтобы изменение значений общих переменных осуществлялось в каждый момент времени только одним единственным потоком - иными словами, необходимо обеспечить взаимное исключение (mutual exclusion) потоков при работе с общими данными. В OpenMP взаимоисключение может быть организовано при помощи неделимых (atomic) операций, механизма критических секций (critical sections) или специального типа семафоров - замков (locks).
